{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "(ANS)RNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/cheonbok94/DeepLearningLecture/blob/master/(ANS)RNN.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "gZJZeFR6InJz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#1,2 http://pytorch.org/\n",
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.3.0.post4-{platform}-linux_x86_64.whl torchvision\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FDEKCo7WSjeG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "767ab79e-a047-4b91-c666-af85f8a87fba"
      },
      "cell_type": "code",
      "source": [
        "# 3. authorization for using Google Drive\n",
        "!pip install -U -q PyDrive\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# PyDrive reference:\n",
        "# https://googledrive.github.io/PyDrive/docs/build/html/index.html\n",
        "\n",
        "# 2. Create & upload a file text file.\n",
        "uploaded = drive.CreateFile({'title': 'Sample upload.txt'})\n",
        "uploaded.SetContentString('Sample upload file content')\n",
        "uploaded.Upload()\n",
        "print('Uploaded file with ID {}'.format(uploaded.get('id')))\n",
        "\n",
        "# 3. Load a file by ID and print its contents.\n",
        "downloaded = drive.CreateFile({'id': uploaded.get('id')})\n",
        "print('Downloaded content \"{}\"'.format(downloaded.GetContentString()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uploaded file with ID 1xtOKOMm9YrlwrIx9yj1P3O0HJVH3EDYM\n",
            "Downloaded content \"Sample upload file content\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-XWaZoZ2gxSZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "843cab66-9815-4e09-fb79-556b77b8fc3a"
      },
      "cell_type": "code",
      "source": [
        "# 4. connect to Google Drive\n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
        "\n",
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gpg: keybox '/tmp/tmpbhuuoysx/pubring.gpg' created\n",
            "gpg: /tmp/tmpbhuuoysx/trustdb.gpg: trustdb created\n",
            "gpg: key AD5F235DF639B041: public key \"Launchpad PPA for Alessandro Strada\" imported\n",
            "gpg: Total number processed: 1\n",
            "gpg:               imported: 1\n",
            "Warning: apt-key output should not be parsed (stdout is not a terminal)\n",
            "··········\n",
            "fuse: mountpoint is not empty\n",
            "fuse: if you are sure this is safe, use the 'nonempty' mount option\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MUaRuZ-oi9P3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gFgpROcDi4Mt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "bfd484a4-4d1a-46a6-d496-8749e7041dde"
      },
      "cell_type": "code",
      "source": [
        "os.listdir('./drive/4일차')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['제목 없는 문서.odt (74cd90d2)',\n",
              " '1_28 발제 준비 .odt',\n",
              " 'Summarization of 2017 Deep NLP.pptx',\n",
              " '1주차.pdf',\n",
              " 'Machine learning with Calculus - week1.pdf',\n",
              " '2주차.pdf',\n",
              " '3주차_선형대수 입문 기본.pdf',\n",
              " '제목 없는 문서.odt',\n",
              " '2018R1_Research',\n",
              " '새 파일 2018-03-29.pdf',\n",
              " '04_08발제준비.odt',\n",
              " '새 파일 2018-04-08.pdf',\n",
              " 'Latent Constraints.pptx',\n",
              " 'Fundamental Mathematical Machine learning.odt',\n",
              " '제목 없는 스프레드시트.ods',\n",
              " '1주차.pptx',\n",
              " '제목 없는 설문지의 사본.zip',\n",
              " '제목 없는 설문지.zip',\n",
              " 'others',\n",
              " 'lecture']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "4blR2gaEIOA4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 패키지들을 불러옵니다\n",
        "import torch # load torch package\n",
        "from torch.autograd import Variable # Load Variable Package\n",
        "import torch.nn as nn  # Load Neural Network Layer\n",
        "import torch.nn.functional as F # pyTorch function  불러오기  \n",
        "import numpy as np # numpy 연산을 위한 package 입니다. "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2ByAMzP0TXQA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8c00dcb3-ec42-4fc2-fd90-c1ab024454b3"
      },
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available() # CUDA is available 을 통해 cuda 연동 가능성 확인 "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "s_3-PcjJLTG3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Movie Sentiment Predcition"
      ]
    },
    {
      "metadata": {
        "id": "jqGmdwFXfyEy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "metadata": {
        "id": "p5HT64jaf4Kb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8sXLLUznWDJu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "저장된 데이터 위치로 가서 해당 파일을 불러옵니다."
      ]
    },
    {
      "metadata": {
        "id": "m_f7FvEgf51z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('./drive/4일차/0_movie_300.txt') as f:\n",
        "  movies = json.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g1i1qXBbf487",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "outputId": "c0fd9a0f-ddf6-47c2-a0a9-5cd559901af4"
      },
      "cell_type": "code",
      "source": [
        "# 샘플 구경\n",
        "for i in range(12,16):\n",
        "  for j in range(4):\n",
        "    score = movies[i]['ratings'][j]['score']\n",
        "    reple = movies[i]['ratings'][j]['reple']\n",
        "    print(score,reple) # 보통의 데이터는 이렇게 우리의 자연어로 처리가 되어 있습니다. 해당 문장을 우리는 컴퓨터가 이해가능한 숫자로 표시를 해야 합니다. "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8 한글 자막이 없어, 화면으로만 즐긴 영화.. 미안해서 8점..\n",
            "6 두뇌 대결이 치열하지도 않고 보고 나서 남는 것도 없었다. 그냥 게리 올드만과 케빈 베이컨의 옛 모습을 보는 것에 만족했을 뿐\n",
            "8 개인적으로 재밌게 본 영화..\n",
            "7 훌륭한 미장센과 배우들의 호연에 비해 아쉬운 연출력\n",
            "9 또다른 시각에서의 한국전쟁. 전쟁 속 시골 마을 과부의 인생역정을 통해 한 많은 우리 민족과 역사의 슬픔을 다시금 느끼게 해 준 영화. 그리고 인간 내면의 이기심과 추악하고 더러운 모습에 또 한번 놀라다. 연말에 또 한편의 보석같은 한국영화를 찾았다!\n",
            "10 가슴 아픈 영화,,\n",
            "10 어렸을때 봤지만 크게 감명받은 영화\n",
            "9 개봉당시  대학생이었는데   영화가  너무  슬퍼서 한동안  자리에서 앉아  있었던 기억이  나네요..\n",
            "10 요즘 이상한 영화들보다  100배 재미있다.\n",
            "10 최고의 변종 전쟁영화. 쓰리 킹즈는 이 영화에 빚을 졌다\n",
            "10 이제 껀 본 영화 들중의 수작\n",
            "8 최고의 전쟁영화 중 하나...전쟁영화라기 보다 유쾌한 도적들의 영화? 역시 돈이 최고...^^\n",
            "10 나쁘진않다 딱 그정도이다.\n",
            "9 볼만하다  아 파란만장한 아프리카의 여인이여\n",
            "10 웬만한 영화보다 훨 나으네요~ 51년작 치고는 매우 수작임\n",
            "2 그렇게 좋게평가될 영화는아닌듯 일단 전체적전개가 그렇게 자연스럽지가않음\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BikPDuwnjtM-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 전처리 후의 데이터\n",
        "with open('./drive/4일차/data3.pkl','rb') as f:\n",
        "  i2v = pickle.load(f)\n",
        "  v2i = pickle.load(f)\n",
        "  tr_X = pickle.load(f)\n",
        "  tr_y = pickle.load(f)\n",
        "  t_X = pickle.load(f)\n",
        "  t_y = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sN6qNMMwkGws",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 18035
        },
        "outputId": "bb179897-885f-4882-ece0-ae71d7097637"
      },
      "cell_type": "code",
      "source": [
        "# dictionaries 우리는 다음과 같이 index -> word로 가는 dictonary 와 vocabulary에서 index로 가는 dictonary 를 둘 다 생성해야 합니다. 이렇게 해야 우리는 컴퓨터가 이해할수 있는 숫자로 보내주는 것 , 사람이 이해할 수 있는 결과로 보여주도록 하는 두가지 \n",
        "# Mapping을 사용하게 됩니다. \n",
        "i2v # 숫자에서 단어로\n",
        "v2i # 단어에서 숫자로 밑에 보이는 output이 v2i의 결과 입니다. "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<PAD>': 0,\n",
              " '.': 1,\n",
              " '이': 2,\n",
              " '영화': 3,\n",
              " '다': 4,\n",
              " '가': 5,\n",
              " '..': 6,\n",
              " '는': 7,\n",
              " '에': 8,\n",
              " '을': 9,\n",
              " '도': 10,\n",
              " '의': 11,\n",
              " '은': 12,\n",
              " '...': 13,\n",
              " '들': 14,\n",
              " '고': 15,\n",
              " '한': 16,\n",
              " '만': 17,\n",
              " ',': 18,\n",
              " '를': 19,\n",
              " '요': 20,\n",
              " '너무': 21,\n",
              " '음': 22,\n",
              " '좋': 23,\n",
              " '게': 24,\n",
              " '지': 25,\n",
              " '서': 26,\n",
              " '것': 27,\n",
              " '나': 28,\n",
              " '는데': 29,\n",
              " '봤': 30,\n",
              " '스토리': 31,\n",
              " '적': 32,\n",
              " '연기': 33,\n",
              " '?': 34,\n",
              " '거': 35,\n",
              " '듯': 36,\n",
              " '으로': 37,\n",
              " '로': 38,\n",
              " '점': 39,\n",
              " '했': 40,\n",
              " '습니다': 41,\n",
              " '볼': 42,\n",
              " '진짜': 43,\n",
              " '았': 44,\n",
              " '어요': 45,\n",
              " '지만': 46,\n",
              " '정말': 47,\n",
              " '배우': 48,\n",
              " '데': 49,\n",
              " '안': 50,\n",
              " '과': 51,\n",
              " '그냥': 52,\n",
              " '좀': 53,\n",
              " '내': 54,\n",
              " '!': 55,\n",
              " '보고': 56,\n",
              " '인': 57,\n",
              " '에서': 58,\n",
              " '하고': 59,\n",
              " '~': 60,\n",
              " '수': 61,\n",
              " '내용': 62,\n",
              " '못': 63,\n",
              " '평점': 64,\n",
              " '잘': 65,\n",
              " '보다': 66,\n",
              " '던': 67,\n",
              " '재미': 68,\n",
              " '와': 69,\n",
              " '아': 70,\n",
              " '....': 71,\n",
              " '네요': 72,\n",
              " '그': 73,\n",
              " '보는': 74,\n",
              " '더': 75,\n",
              " '기대': 76,\n",
              " '있': 77,\n",
              " '였': 78,\n",
              " '아니': 79,\n",
              " '라': 80,\n",
              " '액션': 81,\n",
              " '네': 82,\n",
              " '면': 83,\n",
              " '생각': 84,\n",
              " '하는': 85,\n",
              " '사람': 86,\n",
              " '본': 87,\n",
              " '1': 88,\n",
              " '느낌': 89,\n",
              " '감동': 90,\n",
              " '없는': 91,\n",
              " 'ㅋㅋ': 92,\n",
              " '별로': 93,\n",
              " '재미없': 94,\n",
              " ';': 95,\n",
              " '시간': 96,\n",
              " '왜': 97,\n",
              " '말': 98,\n",
              " '봐': 99,\n",
              " '돈': 100,\n",
              " '정도': 101,\n",
              " '이런': 102,\n",
              " '뭐': 103,\n",
              " '장면': 104,\n",
              " '겠': 105,\n",
              " '건': 106,\n",
              " '많이': 107,\n",
              " '2': 108,\n",
              " '알': 109,\n",
              " '같은': 110,\n",
              " '할': 111,\n",
              " '까지': 112,\n",
              " '이다': 113,\n",
              " '감독': 114,\n",
              " '있는': 115,\n",
              " '니다': 116,\n",
              " '괜찮': 117,\n",
              " '함': 118,\n",
              " '중간': 119,\n",
              " '줄': 120,\n",
              " '하': 121,\n",
              " '없다': 122,\n",
              " '없고': 123,\n",
              " '마지막': 124,\n",
              " '소재': 125,\n",
              " '보면': 126,\n",
              " '!!': 127,\n",
              " '그런': 128,\n",
              " '저': 129,\n",
              " '하지만': 130,\n",
              " '반전': 131,\n",
              " '부분': 132,\n",
              " '결말': 133,\n",
              " '전개': 134,\n",
              " '까': 135,\n",
              " '야': 136,\n",
              " '때': 137,\n",
              " '3': 138,\n",
              " '솔직히': 139,\n",
              " 'ㅋ': 140,\n",
              " '실망': 141,\n",
              " '어': 142,\n",
              " '중': 143,\n",
              " '하나': 144,\n",
              " '처음': 145,\n",
              " '연출': 146,\n",
              " '주': 147,\n",
              " '아깝': 148,\n",
              " '완전': 149,\n",
              " '&#': 150,\n",
              " '엔': 151,\n",
              " '조금': 152,\n",
              " '아닌': 153,\n",
              " '때문': 154,\n",
              " '모르': 155,\n",
              " '보기': 156,\n",
              " '웹툰': 157,\n",
              " '임': 158,\n",
              " 'ㅠㅠ': 159,\n",
              " '성': 160,\n",
              " 'ㅋㅋㅋ': 161,\n",
              " '끝': 162,\n",
              " '아쉽': 163,\n",
              " '최고': 164,\n",
              " '으면': 165,\n",
              " '있었': 166,\n",
              " '난': 167,\n",
              " '원작': 168,\n",
              " '하다': 169,\n",
              " '없': 170,\n",
              " '그래도': 171,\n",
              " '니': 172,\n",
              " '입니': 173,\n",
              " '재밌게': 174,\n",
              " '분': 175,\n",
              " '알바': 176,\n",
              " '었': 177,\n",
              " '해서': 178,\n",
              " '역시': 179,\n",
              " '잼': 180,\n",
              " '뭔가': 181,\n",
              " '10': 182,\n",
              " '다는': 183,\n",
              " '이렇게': 184,\n",
              " '이건': 185,\n",
              " '이야기': 186,\n",
              " '그리고': 187,\n",
              " '되': 188,\n",
              " '용': 189,\n",
              " '같다': 190,\n",
              " '싶': 191,\n",
              " '재밌었': 192,\n",
              " '해': 193,\n",
              " '개': 194,\n",
              " '않았': 195,\n",
              " '같아': 196,\n",
              " '편': 197,\n",
              " '없이': 198,\n",
              " '하게': 199,\n",
              " 'ㅡㅡ': 200,\n",
              " '억지': 201,\n",
              " '부터': 202,\n",
              " '랑': 203,\n",
              " '다고': 204,\n",
              " '감': 205,\n",
              " '라고': 206,\n",
              " '없었': 207,\n",
              " '작품': 208,\n",
              " '이순신': 209,\n",
              " '된': 210,\n",
              " '이나': 211,\n",
              " '근데': 212,\n",
              " '초반': 213,\n",
              " '인데': 214,\n",
              " '긴장감': 215,\n",
              " '딱': 216,\n",
              " '두': 217,\n",
              " '연기력': 218,\n",
              " '유치': 219,\n",
              " '좀비': 220,\n",
              " '참': 221,\n",
              " '드라마': 222,\n",
              " '후반': 223,\n",
              " '주인공': 224,\n",
              " '라는': 225,\n",
              " 'ㅎㅎ': 226,\n",
              " '다면': 227,\n",
              " '으나': 228,\n",
              " '씨': 229,\n",
              " '기': 230,\n",
              " '에는': 231,\n",
              " '뻔한': 232,\n",
              " '다른': 233,\n",
              " '냐': 234,\n",
              " '전': 235,\n",
              " '걸': 236,\n",
              " ';;': 237,\n",
              " '여자': 238,\n",
              " '^^': 239,\n",
              " 'ㅠ': 240,\n",
              " '39': 241,\n",
              " '5': 242,\n",
              " '이었': 243,\n",
              " '같': 244,\n",
              " '나름': 245,\n",
              " '화': 246,\n",
              " '~~': 247,\n",
              " '약간': 248,\n",
              " '님': 249,\n",
              " '캐릭터': 250,\n",
              " '만든': 251,\n",
              " '짱': 252,\n",
              " '넘': 253,\n",
              " '여': 254,\n",
              " '눈': 255,\n",
              " '이고': 256,\n",
              " '진': 257,\n",
              " '않': 258,\n",
              " '않고': 259,\n",
              " '대': 260,\n",
              " '일': 261,\n",
              " '이랑': 262,\n",
              " '허': 263,\n",
              " '쓰레기': 264,\n",
              " '인지': 265,\n",
              " '7': 266,\n",
              " '자체': 267,\n",
              " '수준': 268,\n",
              " '최악': 269,\n",
              " '뿐': 270,\n",
              " '없어': 271,\n",
              " '왔': 272,\n",
              " '있다': 273,\n",
              " '긴': 274,\n",
              " '웃음': 275,\n",
              " '했지만': 276,\n",
              " '아이': 277,\n",
              " '한번': 278,\n",
              " '몰입': 279,\n",
              " '이영화': 280,\n",
              " '짜': 281,\n",
              " '애': 282,\n",
              " '다시': 283,\n",
              " '김수현': 284,\n",
              " '??': 285,\n",
              " '보여': 286,\n",
              " '!!!': 287,\n",
              " '이해': 288,\n",
              " '자': 289,\n",
              " '많은': 290,\n",
              " '지루한': 291,\n",
              " '나오는': 292,\n",
              " '에게': 293,\n",
              " '하지': 294,\n",
              " '영상': 295,\n",
              " '별': 296,\n",
              " '급': 297,\n",
              " '보지': 298,\n",
              " '무슨': 299,\n",
              " '되는': 300,\n",
              " '이상': 301,\n",
              " '관객': 302,\n",
              " '않은': 303,\n",
              " '매력': 304,\n",
              " '이라': 305,\n",
              " '다가': 306,\n",
              " '대박': 307,\n",
              " '또': 308,\n",
              " '개인': 309,\n",
              " '남자': 310,\n",
              " '코믹': 311,\n",
              " '사랑': 312,\n",
              " '않는': 313,\n",
              " '신': 314,\n",
              " '밖에': 315,\n",
              " '그저': 316,\n",
              " '역사': 317,\n",
              " '내내': 318,\n",
              " '코미디': 319,\n",
              " '갔': 320,\n",
              " '지도': 321,\n",
              " '무섭': 322,\n",
              " '있고': 323,\n",
              " '만들': 324,\n",
              " '재밌다': 325,\n",
              " '웃기': 326,\n",
              " '나온': 327,\n",
              " '재미있게': 328,\n",
              " '인가': 329,\n",
              " '있어': 330,\n",
              " '큰': 331,\n",
              " '스릴러': 332,\n",
              " '기분': 333,\n",
              " '재밌': 334,\n",
              " '지루했': 335,\n",
              " '8': 336,\n",
              " '아쉬운': 337,\n",
              " '합': 338,\n",
              " '길': 339,\n",
              " '현실': 340,\n",
              " '움': 341,\n",
              " '개연': 342,\n",
              " '친구': 343,\n",
              " '전혀': 344,\n",
              " '킬링타임': 345,\n",
              " '하네': 346,\n",
              " '주고': 347,\n",
              " '준': 348,\n",
              " '재미있었': 349,\n",
              " '대한': 350,\n",
              " '전체': 351,\n",
              " '건지': 352,\n",
              " '면서': 353,\n",
              " '4': 354,\n",
              " '꼭': 355,\n",
              " '예고편': 356,\n",
              " '재밌어': 357,\n",
              " '살': 358,\n",
              " '기대했': 359,\n",
              " '그렇': 360,\n",
              " '지루함': 361,\n",
              " '6': 362,\n",
              " '만들었': 363,\n",
              " '짜증': 364,\n",
              " '력': 365,\n",
              " '보': 366,\n",
              " '갈수록': 367,\n",
              " '아쉬움': 368,\n",
              " '는지': 369,\n",
              " '처럼': 370,\n",
              " 'ㅎ': 371,\n",
              " '한국': 372,\n",
              " '마음': 373,\n",
              " '영화관': 374,\n",
              " '사실': 375,\n",
              " '지루하고': 376,\n",
              " '될': 377,\n",
              " '.....': 378,\n",
              " '캐스팅': 379,\n",
              " '이라는': 380,\n",
              " '나왔': 381,\n",
              " 'ㅋㅋㅋㅋ': 382,\n",
              " '부': 383,\n",
              " '어이': 384,\n",
              " '시리즈': 385,\n",
              " '울': 386,\n",
              " '중반': 387,\n",
              " '걍': 388,\n",
              " '을까': 389,\n",
              " '보단': 390,\n",
              " 'ㅜㅜ': 391,\n",
              " '지는': 392,\n",
              " '스릴': 393,\n",
              " '물': 394,\n",
              " '은데': 395,\n",
              " '그나마': 396,\n",
              " '보다는': 397,\n",
              " '대사': 398,\n",
              " '-': 399,\n",
              " '기대하고': 400,\n",
              " '하면': 401,\n",
              " '특히': 402,\n",
              " '극': 403,\n",
              " '만큼': 404,\n",
              " '엉': 405,\n",
              " '보러': 406,\n",
              " '계속': 407,\n",
              " '진심': 408,\n",
              " '설정': 409,\n",
              " '최민식': 410,\n",
              " '든': 411,\n",
              " '리': 412,\n",
              " '허무': 413,\n",
              " '영화로': 414,\n",
              " '몰입도': 415,\n",
              " '어떻': 416,\n",
              " '가족': 417,\n",
              " '이네': 418,\n",
              " '시나리오': 419,\n",
              " '남는': 420,\n",
              " '공포': 421,\n",
              " '한국영': 422,\n",
              " '안되': 423,\n",
              " '속': 424,\n",
              " '아주': 425,\n",
              " ',,': 426,\n",
              " '같이': 427,\n",
              " '있지': 428,\n",
              " '가장': 429,\n",
              " '인간': 430,\n",
              " '제': 431,\n",
              " 'ㅡ': 432,\n",
              " '후': 433,\n",
              " '그렇게': 434,\n",
              " '졸리': 435,\n",
              " '우리': 436,\n",
              " '제대로': 437,\n",
              " '구성': 438,\n",
              " '아까운': 439,\n",
              " '극장': 440,\n",
              " '재밌는': 441,\n",
              " '남': 442,\n",
              " '점수': 443,\n",
              " '치': 444,\n",
              " '진부': 445,\n",
              " '(': 446,\n",
              " '라면': 447,\n",
              " '가는': 448,\n",
              " '시': 449,\n",
              " '보세': 450,\n",
              " '차라리': 451,\n",
              " '좋아하는': 452,\n",
              " 'CG': 453,\n",
              " '아쉬웠': 454,\n",
              " '비해': 455,\n",
              " '모두': 456,\n",
              " '오랜만': 457,\n",
              " '없네': 458,\n",
              " '34': 459,\n",
              " '씬': 460,\n",
              " '엄청': 461,\n",
              " '이유': 462,\n",
              " '만들어': 463,\n",
              " '개봉': 464,\n",
              " '공감': 465,\n",
              " '한테': 466,\n",
              " '모든': 467,\n",
              " '들었': 468,\n",
              " '추천': 469,\n",
              " '그닥': 470,\n",
              " '나쁘': 471,\n",
              " '굿': 472,\n",
              " '보니': 473,\n",
              " '요소': 474,\n",
              " '가지': 475,\n",
              " ')': 476,\n",
              " '공포영화': 477,\n",
              " '안되는': 478,\n",
              " '않아': 479,\n",
              " '모습': 480,\n",
              " '뒤': 481,\n",
              " '위한': 482,\n",
              " '주는': 483,\n",
              " '나와': 484,\n",
              " '뭔': 485,\n",
              " '장르': 486,\n",
              " '지금': 487,\n",
              " '에도': 488,\n",
              " '질': 489,\n",
              " '하기': 490,\n",
              " '기억': 491,\n",
              " '같네': 492,\n",
              " '니까': 493,\n",
              " '아님': 494,\n",
              " '눈물': 495,\n",
              " '소리': 496,\n",
              " '영화인': 497,\n",
              " '다만': 498,\n",
              " '인물': 499,\n",
              " '번': 500,\n",
              " '오': 501,\n",
              " '볼거리': 502,\n",
              " '식': 503,\n",
              " '지루': 504,\n",
              " '9': 505,\n",
              " '이제': 506,\n",
              " '한데': 507,\n",
              " '이지만': 508,\n",
              " '앞': 509,\n",
              " '명': 510,\n",
              " '우리나라': 511,\n",
              " '흥행': 512,\n",
              " '스케일': 513,\n",
              " '마블': 514,\n",
              " '나올': 515,\n",
              " '쓰': 516,\n",
              " '아요': 517,\n",
              " '무': 518,\n",
              " '팬': 519,\n",
              " '아까': 520,\n",
              " '영': 521,\n",
              " '동호': 522,\n",
              " '분들': 523,\n",
              " '며': 524,\n",
              " '이하': 525,\n",
              " '부족한': 526,\n",
              " '봄': 527,\n",
              " 'ㅜ': 528,\n",
              " '그랬': 529,\n",
              " '마술': 530,\n",
              " '제일': 531,\n",
              " '꺼': 532,\n",
              " '스럽': 533,\n",
              " '그러나': 534,\n",
              " '말고': 535,\n",
              " '간': 536,\n",
              " '보았': 537,\n",
              " '빼고': 538,\n",
              " '+': 539,\n",
              " '뭘': 540,\n",
              " '년': 541,\n",
              " '분위기': 542,\n",
              " '가볍': 543,\n",
              " '재밋': 544,\n",
              " '음악': 545,\n",
              " '햇': 546,\n",
              " '로맨스': 547,\n",
              " '려고': 548,\n",
              " '보시': 549,\n",
              " '만드는': 550,\n",
              " '노잼': 551,\n",
              " '요즘': 552,\n",
              " '래': 553,\n",
              " '몇': 554,\n",
              " '마무리': 555,\n",
              " '무서운': 556,\n",
              " '가슴': 557,\n",
              " '그래서': 558,\n",
              " '스러운': 559,\n",
              " '제목': 560,\n",
              " '이정재': 561,\n",
              " '없지': 562,\n",
              " '매우': 563,\n",
              " '그럭저럭': 564,\n",
              " '만화': 565,\n",
              " '지루하다': 566,\n",
              " '집중': 567,\n",
              " '얼굴': 568,\n",
              " '주연': 569,\n",
              " '싶은': 570,\n",
              " '엔딩': 571,\n",
              " '싶다': 572,\n",
              " '놓': 573,\n",
              " '앗': 574,\n",
              " '무엇': 575,\n",
              " '라서': 576,\n",
              " '절대': 577,\n",
              " '관람': 578,\n",
              " '화려한': 579,\n",
              " '죠': 580,\n",
              " '세': 581,\n",
              " '다음': 582,\n",
              " '다소': 583,\n",
              " '일본': 584,\n",
              " '날': 585,\n",
              " '미국': 586,\n",
              " '타임': 587,\n",
              " '등': 588,\n",
              " '살짝': 589,\n",
              " '이야': 590,\n",
              " '단': 591,\n",
              " '전투': 592,\n",
              " '훨씬': 593,\n",
              " '높은': 594,\n",
              " '건가': 595,\n",
              " '마세': 596,\n",
              " '아까워': 597,\n",
              " '다니': 598,\n",
              " '꽤': 599,\n",
              " '군': 600,\n",
              " '이란': 601,\n",
              " '만하': 602,\n",
              " '아직': 603,\n",
              " '이라고': 604,\n",
              " '이번': 605,\n",
              " '구': 606,\n",
              " '더라': 607,\n",
              " '잔인': 608,\n",
              " '아니었': 609,\n",
              " '지루해': 610,\n",
              " '쳐': 611,\n",
              " '구나': 612,\n",
              " '안보': 613,\n",
              " '해도': 614,\n",
              " '술': 615,\n",
              " '간만': 616,\n",
              " '문제': 617,\n",
              " '많아': 618,\n",
              " '당': 619,\n",
              " '지루하지': 620,\n",
              " '~~~': 621,\n",
              " '이후': 622,\n",
              " '의미': 623,\n",
              " '결국': 624,\n",
              " '집': 625,\n",
              " '아들': 626,\n",
              " '에요': 627,\n",
              " '상황': 628,\n",
              " 'OO': 629,\n",
              " '실화': 630,\n",
              " '놈': 631,\n",
              " '작가': 632,\n",
              " '이순신장군': 633,\n",
              " '도대체': 634,\n",
              " '감정': 635,\n",
              " '많': 636,\n",
              " '맘': 637,\n",
              " '정신': 638,\n",
              " '개그': 639,\n",
              " '함께': 640,\n",
              " '오늘': 641,\n",
              " '장군': 642,\n",
              " '전반': 643,\n",
              " '점도': 644,\n",
              " '장난': 645,\n",
              " '미': 646,\n",
              " '욕': 647,\n",
              " '인상': 648,\n",
              " '해야': 649,\n",
              " '났': 650,\n",
              " '영웅': 651,\n",
              " '상': 652,\n",
              " '힘': 653,\n",
              " '류': 654,\n",
              " '휴': 655,\n",
              " '탄탄': 656,\n",
              " '재미있': 657,\n",
              " '여주': 658,\n",
              " '런가': 659,\n",
              " '믿고': 660,\n",
              " '편이': 661,\n",
              " '참신': 662,\n",
              " '흐름': 663,\n",
              " '아서': 664,\n",
              " '곤': 665,\n",
              " '위해': 666,\n",
              " '냥': 667,\n",
              " '초': 668,\n",
              " '더니': 669,\n",
              " '줘': 670,\n",
              " '군요': 671,\n",
              " '송강호': 672,\n",
              " '던데': 673,\n",
              " '가서': 674,\n",
              " '강추': 675,\n",
              " '공유': 676,\n",
              " '을텐데': 677,\n",
              " '많았': 678,\n",
              " '구요': 679,\n",
              " '됐': 680,\n",
              " '되었': 681,\n",
              " '그러': 682,\n",
              " '너무나': 683,\n",
              " '둘': 684,\n",
              " '충분히': 685,\n",
              " '소름': 686,\n",
              " '전부': 687,\n",
              " ',,,': 688,\n",
              " '찝': 689,\n",
              " '마': 690,\n",
              " '첨': 691,\n",
              " '엄마': 692,\n",
              " '흥미진진': 693,\n",
              " '온': 694,\n",
              " '그대로': 695,\n",
              " '무난': 696,\n",
              " '재미있어': 697,\n",
              " '스파이더맨': 698,\n",
              " '에서는': 699,\n",
              " '여운': 700,\n",
              " '조연': 701,\n",
              " '히': 702,\n",
              " '않다': 703,\n",
              " '반': 704,\n",
              " '머': 705,\n",
              " '산만': 706,\n",
              " '나도': 707,\n",
              " '혼자': 708,\n",
              " '답': 709,\n",
              " '안젤리나': 710,\n",
              " '편집': 711,\n",
              " '거의': 712,\n",
              " '&': 713,\n",
              " '먼': 714,\n",
              " '느끼': 715,\n",
              " '크': 716,\n",
              " '새로운': 717,\n",
              " '마다': 718,\n",
              " '전편': 719,\n",
              " 'D': 720,\n",
              " '부족': 721,\n",
              " '딴': 722,\n",
              " '일단': 723,\n",
              " '판타지': 724,\n",
              " '그것': 725,\n",
              " '전작': 726,\n",
              " '잔잔': 727,\n",
              " '%': 728,\n",
              " '억지로': 729,\n",
              " '0': 730,\n",
              " '상영': 731,\n",
              " '겟': 732,\n",
              " '주제': 733,\n",
              " '액션영화': 734,\n",
              " '교훈': 735,\n",
              " '어설픈': 736,\n",
              " '재미있는': 737,\n",
              " '웃긴': 738,\n",
              " '써': 739,\n",
              " '줬': 740,\n",
              " '책': 741,\n",
              " '맞는': 742,\n",
              " '명량': 743,\n",
              " '는걸': 744,\n",
              " '어서': 745,\n",
              " '떨어지': 746,\n",
              " '막': 747,\n",
              " '인생': 748,\n",
              " '......': 749,\n",
              " '그래': 750,\n",
              " '비추': 751,\n",
              " '재밌네': 752,\n",
              " '/': 753,\n",
              " '재': 754,\n",
              " '얘기': 755,\n",
              " '판': 756,\n",
              " '라도': 757,\n",
              " '죽는': 758,\n",
              " ';;;': 759,\n",
              " '유쾌': 760,\n",
              " '동안': 761,\n",
              " '란': 762,\n",
              " '보게': 763,\n",
              " '여기': 764,\n",
              " '배경': 765,\n",
              " '아저씨': 766,\n",
              " '보이': 767,\n",
              " '기도': 768,\n",
              " '똑같': 769,\n",
              " '총': 770,\n",
              " '우': 771,\n",
              " '오락': 772,\n",
              " '싶었': 773,\n",
              " '어떤': 774,\n",
              " '컸': 775,\n",
              " '얼마나': 776,\n",
              " '20': 777,\n",
              " '머리': 778,\n",
              " '흥미': 779,\n",
              " '만은': 780,\n",
              " '맛': 781,\n",
              " '범인': 782,\n",
              " '한마디': 783,\n",
              " '아무리': 784,\n",
              " '있으': 785,\n",
              " '죽': 786,\n",
              " '♥': 787,\n",
              " '갑자기': 788,\n",
              " '그래픽': 789,\n",
              " '역할': 790,\n",
              " '막장': 791,\n",
              " '어느': 792,\n",
              " '흠': 793,\n",
              " '빨': 794,\n",
              " '그게': 795,\n",
              " '디': 796,\n",
              " '받아': 797,\n",
              " '평론가': 798,\n",
              " '???': 799,\n",
              " '땜': 800,\n",
              " '대체': 801,\n",
              " '재밌고': 802,\n",
              " '그런데': 803,\n",
              " '먹': 804,\n",
              " '시대': 805,\n",
              " '대로': 806,\n",
              " '!!!!': 807,\n",
              " '전형': 808,\n",
              " '히어로': 809,\n",
              " '같았': 810,\n",
              " '순간': 811,\n",
              " '평': 812,\n",
              " '굉장히': 813,\n",
              " '이리': 814,\n",
              " '확실히': 815,\n",
              " '귀신': 816,\n",
              " '오히려': 817,\n",
              " '예상': 818,\n",
              " '쯤': 819,\n",
              " '버린': 820,\n",
              " '풀어': 821,\n",
              " '됨': 822,\n",
              " '으로는': 823,\n",
              " '크게': 824,\n",
              " '다운': 825,\n",
              " '낸': 826,\n",
              " '뻔': 827,\n",
              " '복수': 828,\n",
              " '다르': 829,\n",
              " '용이': 830,\n",
              " '졸작': 831,\n",
              " '조': 832,\n",
              " '시작': 833,\n",
              " '연기자': 834,\n",
              " '나오고': 835,\n",
              " '여서': 836,\n",
              " '제발': 837,\n",
              " '생각했': 838,\n",
              " '들어': 839,\n",
              " '줄거리': 840,\n",
              " '좀더': 841,\n",
              " '외': 842,\n",
              " '나옴': 843,\n",
              " '마라': 844,\n",
              " '놓고': 845,\n",
              " '에선': 846,\n",
              " '어디': 847,\n",
              " '비': 848,\n",
              " '배': 849,\n",
              " '까지는': 850,\n",
              " '전쟁': 851,\n",
              " '완성': 852,\n",
              " '사건': 853,\n",
              " '올': 854,\n",
              " '네이버': 855,\n",
              " '빠져': 856,\n",
              " '점점': 857,\n",
              " '이름': 858,\n",
              " '랄': 859,\n",
              " '애국심': 860,\n",
              " '이쁘': 861,\n",
              " \"'\": 862,\n",
              " '재미있다': 863,\n",
              " '굳': 864,\n",
              " '있게': 865,\n",
              " '후회': 866,\n",
              " '별루': 867,\n",
              " '글': 868,\n",
              " '노래': 869,\n",
              " '선': 870,\n",
              " '거리': 871,\n",
              " '누가': 872,\n",
              " '나요': 873,\n",
              " '잠': 874,\n",
              " '쫌': 875,\n",
              " '버리': 876,\n",
              " '인거': 877,\n",
              " '멋진': 878,\n",
              " 'ㅋㅋㅋㅋㅋ': 879,\n",
              " '별점': 880,\n",
              " 'gt': 881,\n",
              " '느낄': 882,\n",
              " '터': 883,\n",
              " '기대한': 884,\n",
              " '누구': 885,\n",
              " '실제': 886,\n",
              " '떨어지는': 887,\n",
              " '그럼': 888,\n",
              " '질질': 889,\n",
              " '화면': 890,\n",
              " '물론': 891,\n",
              " '끝나고': 892,\n",
              " '니콜라스': 893,\n",
              " '있네': 894,\n",
              " '원래': 895,\n",
              " '안된': 896,\n",
              " '러닝': 897,\n",
              " '즐겁': 898,\n",
              " '쓴': 899,\n",
              " 'ㅎㅎㅎ': 900,\n",
              " '보이는': 901,\n",
              " '코드': 902,\n",
              " '홀트': 903,\n",
              " '거기': 904,\n",
              " '세상': 905,\n",
              " 'cg': 906,\n",
              " '소설': 907,\n",
              " '아까웠': 908,\n",
              " '상당히': 909,\n",
              " '잤': 910,\n",
              " '30': 911,\n",
              " '신선한': 912,\n",
              " '존나': 913,\n",
              " '드는': 914,\n",
              " '치고': 915,\n",
              " '안됨': 916,\n",
              " '엇': 917,\n",
              " '어야': 918,\n",
              " '려': 919,\n",
              " '그리': 920,\n",
              " '올해': 921,\n",
              " 'OOO': 922,\n",
              " '힘들': 923,\n",
              " '슬프': 924,\n",
              " '산': 925,\n",
              " '표현': 926,\n",
              " '또한': 927,\n",
              " '전투씬': 928,\n",
              " '대해': 929,\n",
              " '한편': 930,\n",
              " '엉망': 931,\n",
              " '유머': 932,\n",
              " '언제': 933,\n",
              " '점주': 934,\n",
              " '의도': 935,\n",
              " '미친': 936,\n",
              " '멋지': 937,\n",
              " '만큼은': 938,\n",
              " '딸': 939,\n",
              " '어른': 940,\n",
              " '너': 941,\n",
              " '역': 942,\n",
              " '같고': 943,\n",
              " '딱히': 944,\n",
              " '간다': 945,\n",
              " '평가': 946,\n",
              " '살린': 947,\n",
              " '뜬금': 948,\n",
              " '들이': 949,\n",
              " '으': 950,\n",
              " '-_-': 951,\n",
              " '관상': 952,\n",
              " '빼': 953,\n",
              " '다큐': 954,\n",
              " '점준': 955,\n",
              " '야할': 956,\n",
              " '어쩔': 957,\n",
              " '그다지': 958,\n",
              " 'B': 959,\n",
              " '100': 960,\n",
              " '최근': 961,\n",
              " '갑': 962,\n",
              " '발연기': 963,\n",
              " '달': 964,\n",
              " '더욱': 965,\n",
              " '나머지': 966,\n",
              " '보긴': 967,\n",
              " '버렸': 968,\n",
              " '설명': 969,\n",
              " '많고': 970,\n",
              " '나라': 971,\n",
              " '빨리': 972,\n",
              " '쉽': 973,\n",
              " '까진': 974,\n",
              " '조정석': 975,\n",
              " '받': 976,\n",
              " '사회': 977,\n",
              " '성하': 978,\n",
              " '광고': 979,\n",
              " '거야': 980,\n",
              " '져': 981,\n",
              " ':': 982,\n",
              " '황당': 983,\n",
              " '진정': 984,\n",
              " '멜로': 985,\n",
              " '빠순이': 986,\n",
              " '자기': 987,\n",
              " '작': 988,\n",
              " '~!': 989,\n",
              " '장': 990,\n",
              " '실망했': 991,\n",
              " '건데': 992,\n",
              " '포스터': 993,\n",
              " '취향': 994,\n",
              " '기만': 995,\n",
              " '아는': 996,\n",
              " '스타일': 997,\n",
              " '감성': 998,\n",
              " '되어': 999,\n",
              " ...}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "3sbBkg9Dkd7m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "e9b2e425-855b-4b1c-8129-a774b5564575"
      },
      "cell_type": "code",
      "source": [
        "# input data\n",
        "tr_X[70] # 우리의 학습 데이터는 이렇게 문장이 아닌 숫자로 표현이 되게 됩니다. "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[98,\n",
              " 2,\n",
              " 1033,\n",
              " 2387,\n",
              " 247,\n",
              " 2,\n",
              " 3,\n",
              " 19,\n",
              " 74,\n",
              " 27,\n",
              " 12,\n",
              " 1416,\n",
              " 19999,\n",
              " 11,\n",
              " 96,\n",
              " 66,\n",
              " 439,\n",
              " 96,\n",
              " 1250]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "eDxD0ufckPdI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "4a0e5ee2-fcd2-4167-d9f0-03d36fb04661"
      },
      "cell_type": "code",
      "source": [
        "# index list to word list\n",
        "[i2v[word] for word in tr_X[70]] # 해당 문장을 다시 우리가 이해가능한 문자의 세계로 보내볼까요? "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['말',\n",
              " '이',\n",
              " '필요없',\n",
              " '슴',\n",
              " '~~',\n",
              " '이',\n",
              " '영화',\n",
              " '를',\n",
              " '보는',\n",
              " '것',\n",
              " '은',\n",
              " '똥',\n",
              " '<UNK>',\n",
              " '의',\n",
              " '시간',\n",
              " '보다',\n",
              " '아까운',\n",
              " '시간',\n",
              " '이에요']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "ANJ2DJ2mk8RC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4a43b8e2-8507-4fd0-c0ff-6c9a79f96492"
      },
      "cell_type": "code",
      "source": [
        "tr_y[79]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7777777777777778"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "VOErWp0vXUzF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "625c4b7f-6494-43cd-87e9-002446988d72"
      },
      "cell_type": "code",
      "source": [
        "len(tr_X)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "283365"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "jmrcbFsHXcRj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f5db5901-970e-4c1b-8d50-8ba49e63853d"
      },
      "cell_type": "code",
      "source": [
        "len(t_X)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31485"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "NZ9vhYk6XhtA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e2a2e603-69a5-4b26-fe6b-b36d0ab2cef6"
      },
      "cell_type": "code",
      "source": [
        "len(tr_X[0::10])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28337"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "0pwPGae8lLGD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### **Data Preprocessing Summary**\n",
        "\n",
        "i2v : index to vocabulary 해당 되는 index 에 대한 단어의 Dictonary \n",
        "\n",
        "v2i : vocabulary to inde 해당 되는 단어에 대한 index dictonary \n",
        "\n",
        "tr_X : training Data 파일 X (문장갯수 x 문장 단어)\n",
        "\n",
        "tr_y: training Data 파일 y  (문장갯수 y scale value : 1-10 scale : 1 ->0,  6 - > 0.55556(5/9) , 10 ->1)"
      ]
    },
    {
      "metadata": {
        "id": "AhtyfM4SjTjp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def new_data(x,y,max_len = 10,min_len = 6):\n",
        "\tkeep_x = []\n",
        "\tkeep_y = []\n",
        "\tfor i,data in enumerate(x) :\n",
        "\t\tif len(data) <= max_len and len(data) >= min_len:\n",
        "\t\t\tkeep_x.append(data)\n",
        "\t\t\tkeep_y.append(y[i])\n",
        "\treturn keep_x,keep_y\n",
        "\t"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xJDdH3eBjx8i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "simple_x,simple_y = new_data(tr_X,tr_y)\n",
        "simple_tx,simple_ty = new_data(t_X,t_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "duh9y-gpj6FF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "735c6ec3-70ba-44dd-b26d-90e6004c984b"
      },
      "cell_type": "code",
      "source": [
        "len(simple_x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64513"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "metadata": {
        "id": "m842rnrbjPhw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Define Model"
      ]
    },
    {
      "metadata": {
        "id": "T7NK9RrYbRuG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Batch 를 구성해보겠습니다. \n",
        "Q : 우리의 문장에서 항상 단어의 갯수는 일정한가요?\n",
        "\n",
        "문제점: Tensor로 변환하기 위해서는 추가 처리 필요 . eg. Sentence1 : W1 , W2, W3 ,W4 / Sentence : W1 , W2 ,W3 ->  2*3이 맞나요? 2*4가 맞나요? \n",
        "\n",
        "해결법 : Batch * max_length  Tensor로 변환합니다. eg. 2*4의 경우 2 번째 문장의 마지막에 PAD_token을 처리해줍니다. Index 보통 : 0 "
      ]
    },
    {
      "metadata": {
        "id": "zrvON4NJLeUp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def makeBatch(batch_sequences, max_len=100):\n",
        "    batch_sequences = [torch.Tensor(sequence) for sequence in batch_sequences] # Batch 에서 각 Sequence 저장 \n",
        "    lengths = [len(sequence) for sequence in batch_sequences] # Max Length 처리 \n",
        "    output = torch.zeros(len(batch_sequences), max_len) # Batch * Max_length Tensor 생성 \n",
        "    for i, sequence in enumerate(batch_sequences): \n",
        "        length = lengths[i]\n",
        "        output[i, :length] = sequence[:length] # 생성된 Input Tensor에 해당 값을 넣어줍니다. \n",
        "    output = output.long() # 정수 값을 사용할 때는 pytorch에서는 .long() 을 사용합니다.  int()는 사용할 수 없습니다. \n",
        "    return output\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1gUDVb_vMboj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training Step"
      ]
    },
    {
      "metadata": {
        "id": "H_i3YPwkT2dd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "class DataLoader(object):\n",
        "    def __init__(self,data,batch_size,shuffle = True,training= True ):\n",
        "        self.src_data = data[0]\n",
        "        self.trg_data = data[1]\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.iteration = 0\n",
        "        self.max_index = int(len(self.src_data)/batch_size)\n",
        "        if training :\n",
        "            self.init_epoch()\n",
        "    def __iter__(self):\n",
        "      return self\n",
        "    def len_data(self):\n",
        "        return len(self.src_data)\n",
        "    def init_epoch(self):\n",
        "        paired_data = list(zip(self.src_data,self.trg_data))\n",
        "        random.shuffle(paired_data)\n",
        "        self.src_data,self.trg_data = zip(*paired_data)\n",
        "        self.iteration =0\n",
        "    def __next__(self):\n",
        "        return self.next()\n",
        "    def next(self):\n",
        "        while True:\n",
        "            if self.iteration > self.max_index:\n",
        "                self.init_epoch()\n",
        "                raise StopIteration\n",
        "                \n",
        "            selected_src = self.src_data[self.iteration*self.batch_size:(self.iteration+1)*self.batch_size]\n",
        "            len_src = [len(s) for s in selected_src]\n",
        "            selected_src = makeBatch(selected_src,max_len = max(len_src))\n",
        "            selected_trg = self.trg_data[self.iteration*self.batch_size:(self.iteration+1)*self.batch_size]\n",
        "            selected_trg = torch.Tensor(selected_trg)\n",
        "            self.iteration += 1\n",
        "            \n",
        "            return (selected_src,selected_trg)\n",
        "     \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8OzGdDoMWyZw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trainDataLoader = DataLoader((tr_X,tr_y),32,shuffle =True,training =True )\n",
        "testDataLoader = DataLoader((t_X,t_y),32,shuffle = False ,training =False)\n",
        "sim_trainDataLoader = DataLoader((simple_x,simple_y),32,shuffle =True,training =True )  # 데이터가 너무 많아 데이터의 수를 줄여서 사용하기 위해 simple data를 사용해봅니다.\n",
        "sim_testDataLoader = DataLoader((simple_tx[0::10],simple_ty[0::10]),32,shuffle = False ,training =False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l3_0BFXjMg4S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_model (model,dataloader,criterion,optimizer,epoch=4):\n",
        "    step = 0\n",
        "    print (\"[+] Training Start \")\n",
        "    model.train()\n",
        "    for e in range(epoch):\n",
        "        cnt = 0.0\n",
        "        total_loss = 0.0\n",
        "        \n",
        "        for (i,data) in enumerate(dataloader):\n",
        "                x = Variable(data[0]).cuda()\n",
        "                y = Variable(data[1]).cuda()\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(x)\n",
        "                loss = criterion(outputs,y)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                total_loss += loss.data[0]\n",
        "\n",
        "                step+=1\n",
        "        print(\"[+] End of epoch %d avg_loss : %1.3f\" %(e+1,total_loss/step))\n",
        "        step = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pN6l7BhSaaO3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def test_model (model,dataloader,criterion):\n",
        "\t\tstep = 0\n",
        "\t\tmodel.eval()\n",
        "\t\ttotal_loss = 0.0 \n",
        "\t\tfor (i,data) in enumerate(dataloader):\n",
        "\t\t\tx = Variable(data[0]).cuda()\n",
        "\t\t\ty = Variable(data[1]).cuda()\n",
        "\t\t\t\t\t\t\t \n",
        "\t\t\toutputs = model(x)\n",
        "\t\t\tloss = criterion(outputs,y)\n",
        "\t\t\ttotal_loss += loss.data[0]\n",
        "\t\t\t\t\t\t\t\t\n",
        "\t\t\tstep+=1\n",
        "\t\tprint (\"Total avg test loss %1.3f\" %(total_loss/step))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "177__80fc-8_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5fdae9ea-9e85-4e91-e100-60dd4b1bffe5"
      },
      "cell_type": "code",
      "source": [
        "sim_trainDataLoader.max_index"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "885"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "metadata": {
        "id": "aEjj17JrYea0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##  모델을 만들어 봅시다. \n",
        "\n",
        "embedding_dim = 256 \n",
        "hidden_size = 256\n",
        "num layer = 1 \n",
        "bidircetioanl = False \n",
        "Adam Optimizer \n",
        "learning rate = 0.001\n",
        "Loss MSELoss"
      ]
    },
    {
      "metadata": {
        "id": "S_uFvV_HLg_b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class BiRNN(nn.Module):\n",
        "    def __init__(self,vocab_size,embedding_dim,hidden_size,num_layers,bidirectional):\n",
        "        super(BiRNN,self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size,embedding_dim)\n",
        "        self.rnn = nn.RNN(input_size=embedding_dim, hidden_size=hidden_size,  # Rnn의 인자 input_size, hidden_size, num_layers = number of layers , batch_first,bidirectional = Bidicrectonal RNN 사용 \n",
        "                        num_layers=num_layers, batch_first=True, bidirectional=bidirectional)\n",
        "        if self.rnn.bidirectional:\n",
        "            self.W_out = nn.Linear(hidden_size*2,1) # Bidirectional RNN 의 경우 한 방향에 대한 hidden diension 이 2개가 있으므로 *2를 하여 사용합니다. \n",
        "        else:\n",
        "            self.W_out = nn.Linear(hidden_size,1)\n",
        "\n",
        "    def forward(self,x):\n",
        "        b,seq = x.shape\n",
        "        x = self.embedding(x)\n",
        "        outputs, h = self.rnn(x) # RNN input을 넣어줍니다. [b, seq, hid]\n",
        "        outputs = outputs.sum(1) # Sentence Reprensentation 만들기 : rnn outputs (Batch, L,hid) 값들 합치기를 합을(Length) 합니다.[b, hid] -\n",
        "        outputs = self.W_out(outputs) # [b, 1]\n",
        "        return F.sigmoid(outputs.view(b))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TeyQ4XnJd-dk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vocab_size = len(i2v)\n",
        "\n",
        "reg = BiRNN(vocab_size = vocab_size,embedding_dim = 256,hidden_size = 512 ,num_layers = 1 ,bidirectional = False)\n",
        "reg = reg.cuda()\n",
        "criterion = nn.MSELoss()\n",
        "opt = torch.optim.Adam(reg.parameters(),lr= 0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xyLMAsyMjWrg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "b5655b22-75cb-432d-9053-4828715b2376"
      },
      "cell_type": "code",
      "source": [
        "train_model(reg,sim_trainDataLoader,criterion,opt)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[+] Training Start \n",
            "[+] End of epoch 1 avg_loss : 0.068\n",
            "[+] End of epoch 2 avg_loss : 0.052\n",
            "[+] End of epoch 3 avg_loss : 0.044\n",
            "[+] End of epoch 4 avg_loss : 0.037\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3eX-9W9xdsNO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2892abc3-3bd1-47ae-87bc-be229c282dcc"
      },
      "cell_type": "code",
      "source": [
        "test_model(reg,sim_testDataLoader,criterion)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total avg test loss 0.058\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zEH6a_3mTgjo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 일방향 RNN의 한계  -> 왼쪽 단어만 보고 해당 정보를 Encoding ! -> 양방향을 보면 어떨까? --> Bidirectional RNN"
      ]
    },
    {
      "metadata": {
        "id": "k4RREiaxRcfD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "reg = BiRNN(vocab_size = vocab_size,embedding_dim = 256,hidden_size = 256 ,num_layers = 1 ,bidirectional = True)\n",
        "reg = reg.cuda()\n",
        "criterion = nn.MSELoss()\n",
        "opt = torch.optim.Adam(reg.parameters(),lr= 0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YGV0XGD9RiZu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "5ddb96b5-5ad5-477e-e31b-7dfde70a0b2e"
      },
      "cell_type": "code",
      "source": [
        "train_model(reg,sim_trainDataLoader,criterion,opt)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[+] Training Start \n",
            "[+] End of epoch 1 avg_loss : 0.073\n",
            "[+] End of epoch 2 avg_loss : 0.051\n",
            "[+] End of epoch 3 avg_loss : 0.042\n",
            "[+] End of epoch 4 avg_loss : 0.035\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8F4L-mC3eRZJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bf708dae-d482-4734-b694-a3d9204eb767"
      },
      "cell_type": "code",
      "source": [
        "test_model(reg,sim_testDataLoader,criterion)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total avg test loss 0.061\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xCmftk_YUG1_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### RNN 보다 Long Sentence에도 학습을 잘하도록 모델을 만들어보자 -> GRU 로 바꿔보자 "
      ]
    },
    {
      "metadata": {
        "id": "gPzZJaTiUxZG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class BiRNN(nn.Module):\n",
        "    def __init__(self,vocab_size,embedding_dim,hidden_size,num_layers,bidirectional):\n",
        "        super(BiRNN,self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size,embedding_dim)\n",
        "        self.rnn = nn.GRU(input_size=embedding_dim, hidden_size=hidden_size,  # Rnn의 인자 input_size, hidden_size, num_layers = number of layers , batch_first,bidirectional = Bidicrectonal RNN 사용 \n",
        "                        num_layers=num_layers, batch_first=True, bidirectional=bidirectional)\n",
        "        if self.rnn.bidirectional: \n",
        "            self.W_out = nn.Linear(hidden_size*2,1) # Bidirectional RNN 의 경우 한 방향에 대한 hidden diension 이 2개가 있으므로 *2를 하여 사용합니다. \n",
        "        else:\n",
        "            self.W_out = nn.Linear(hidden_size,1)\n",
        "\n",
        "    def forward(self,x):\n",
        "        b,seq = x.shape\n",
        "        x = self.embedding(x)\n",
        "        outputs, h = self.rnn(x) # RNN input을 넣어줍니다. [b, seq, hid]\n",
        "        outputs = outputs.sum(1) # Sentence Reprensentation 만들기 : rnn outputs (Batch, L,hid) 값들 합치기를 합을(Length) 합니다.[b, hid] -\n",
        "        outputs = self.W_out(outputs) # [b, 1]\n",
        "        return F.sigmoid(outputs.view(b))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ix1Sjz6Keq_0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "reg = BiRNN(vocab_size = vocab_size,embedding_dim = 256,hidden_size = 512 ,num_layers = 1 ,bidirectional = False) # Model을 선언해 봅시다. \n",
        "reg = reg.cuda() # cuda 올리기 \n",
        "criterion = nn.MSELoss() # MSE LOSS 선언 \n",
        "opt = torch.optim.Adam(reg.parameters(),lr= 0.001) # OPTIMIZER 부르기 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y4LMNj4ces3x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "5e70a331-314e-4e10-8d04-42e7fef0066d"
      },
      "cell_type": "code",
      "source": [
        "train_model(reg,sim_trainDataLoader,criterion,opt)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[+] Training Start \n",
            "[+] End of epoch 1 avg_loss : 0.068\n",
            "[+] End of epoch 2 avg_loss : 0.052\n",
            "[+] End of epoch 3 avg_loss : 0.044\n",
            "[+] End of epoch 4 avg_loss : 0.036\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "k00P1riMetpI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "57f812ce-8477-4618-98f6-4a7cbf0054a3"
      },
      "cell_type": "code",
      "source": [
        "test_model(reg,sim_testDataLoader,criterion)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total avg test loss 0.064\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mluGVl7fhoJw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###  이번에도 GRU 에 Bidirectional 을 추가하자."
      ]
    },
    {
      "metadata": {
        "id": "IRAotltFhvLk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "reg = BiRNN(vocab_size = vocab_size,embedding_dim = 256,hidden_size = 256 ,num_layers = 1 ,bidirectional = True) # Bidirectonal 옵션을 바꿔 줍시다. \n",
        "reg = reg.cuda()\n",
        "criterion = nn.MSELoss()\n",
        "opt = torch.optim.Adam(reg.parameters(),lr= 0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u7AjT1PEhx3q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "db977409-ac76-4980-e52a-f99c5f20e379"
      },
      "cell_type": "code",
      "source": [
        "train_model(reg,sim_trainDataLoader,criterion,opt)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[+] Training Start \n",
            "[+] End of epoch 1 avg_loss : 0.070\n",
            "[+] End of epoch 2 avg_loss : 0.051\n",
            "[+] End of epoch 3 avg_loss : 0.043\n",
            "[+] End of epoch 4 avg_loss : 0.035\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "curKHxKkh1Ws",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c4394776-c56e-44f9-ac55-dca9d0c9a659"
      },
      "cell_type": "code",
      "source": [
        "test_model(reg,sim_testDataLoader,criterion)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total avg test loss 0.125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mSlzEYgWl32q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 이번에는 더 깊은 Layer 로 변화해보겠습니다. "
      ]
    },
    {
      "metadata": {
        "id": "WbF1Hyd1l_z2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "reg = BiRNN(vocab_size = vocab_size,embedding_dim = 256,hidden_size = 256 ,num_layers = 2 ,bidirectional = True) # Bidirectional 로 바꿔 볼까요? hidden_size는 1/2로 주는게 좋아요 \n",
        "reg = reg.cuda()\n",
        "criterion = nn.MSELoss()\n",
        "opt = torch.optim.Adam(reg.parameters(),lr= 0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_aVS-19RmBfC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "9c9236c1-c6e2-4983-f548-12027864ff5c"
      },
      "cell_type": "code",
      "source": [
        "train_model(reg,sim_trainDataLoader,criterion,opt)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[+] Training Start \n",
            "[+] End of epoch 1 avg_loss : 0.065\n",
            "[+] End of epoch 2 avg_loss : 0.046\n",
            "[+] End of epoch 3 avg_loss : 0.037\n",
            "[+] End of epoch 4 avg_loss : 0.029\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hRaWXGktmCxb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "183675bd-2071-49c9-e1ae-3a6814826124"
      },
      "cell_type": "code",
      "source": [
        "test_model(reg,sim_testDataLoader,criterion)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total avg test loss 0.050\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JHLLO2zZh4u4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Drop out option을 추가해보자 "
      ]
    },
    {
      "metadata": {
        "id": "EY6NDYRPh_Qu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class BiRNN(nn.Module):\n",
        "    def __init__(self,vocab_size,embedding_dim,hidden_size,num_layers,bidirectional):\n",
        "        super(BiRNN,self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size,embedding_dim)\n",
        "        self.rnn = nn.GRU(input_size=embedding_dim, hidden_size=hidden_size,  # Rnn의 인자 input_size, hidden_size, num_layers = number of layers , batch_first,bidirectional = Bidicrectonal RNN 사용 \n",
        "                        num_layers=num_layers, batch_first=True, bidirectional=bidirectional,dropout = 0.2) # 주의 Drop out이 어디 값이 될까요? + Drop out 의 숫자는 유지일까요? 그만큼 drop 시키는 것일까요? # training /test time의 차이는 무엇일까요?\n",
        "        if self.rnn.bidirectional: \n",
        "            self.W_out = nn.Linear(hidden_size*2,1) # Bidirectional RNN 의 경우 한 방향에 대한 hidden diension 이 2개가 있으므로 *2를 하여 사용합니다. \n",
        "        else:\n",
        "            self.W_out = nn.Linear(hidden_size,1)\n",
        "\n",
        "    def forward(self,x):\n",
        "        b,seq = x.shape\n",
        "        x = self.embedding(x)\n",
        "        outputs, h = self.rnn(x) # RNN input을 넣어줍니다. [b, seq, hid]\n",
        "        outputs = outputs.sum(1) # Sentence Reprensentation 만들기 : rnn outputs (Batch, L,hid) 값들 합치기를 합을(Length) 합니다.[b, hid] -\n",
        "        outputs = self.W_out(outputs) # [b, 1]\n",
        "        return F.sigmoid(outputs.view(b))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kHBSbAjkoS5H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "reg = BiRNN(vocab_size = vocab_size,embedding_dim = 256,hidden_size = 256 ,num_layers = 2 ,bidirectional = True) # Bidirectional 로 바꿔 볼까요? hidden_size는 1/2로 주는게 좋아요 \n",
        "reg = reg.cuda()\n",
        "criterion = nn.MSELoss()\n",
        "opt = torch.optim.Adam(reg.parameters(),lr= 0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bFnEUR7ToVMV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "c0c400bf-f69d-4930-fedf-a6db45e426d5"
      },
      "cell_type": "code",
      "source": [
        "train_model(reg,sim_trainDataLoader,criterion,opt)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[+] Training Start \n",
            "[+] End of epoch 1 avg_loss : 0.068\n",
            "[+] End of epoch 2 avg_loss : 0.047\n",
            "[+] End of epoch 3 avg_loss : 0.038\n",
            "[+] End of epoch 4 avg_loss : 0.031\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JeNjHFy9oW3Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3b3193d7-d543-46cf-f83d-7828b83077ff"
      },
      "cell_type": "code",
      "source": [
        "test_model(reg,sim_testDataLoader,criterion)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total avg test loss 0.054\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "O9ieXb_RgOyS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## CNN 기반의 Sentiment Analysis Model (Practive : 그림을 그리면서 코드를 짜보는 연습.)"
      ]
    },
    {
      "metadata": {
        "id": "7AnNi1CHJHJZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CNNReg(nn.Module):\n",
        "    def __init__(self, voca_size, embedding_dim):\n",
        "        super(CNNReg, self).__init__()\n",
        "        self.kernel_size = [2, 3, 4, 5] # CNN -- Window Size 다르게?  Why ? 다양한 Phrase 를 잡는다고 생각 하시면 됩니다. Phrase 는 뭔가요? European Union 이걸 우린 하나 하나로 인식하지 않고 두 글자를 하나의 의미로 인식합니다. 이런 단위가 Phrase입니다.\n",
        "                                        # 이런 Phrase 가 다양하게 Capture 해내기 위해서 우린 다양한 Convolutuin size 를 정하고 사용합니다.\n",
        "        self.channel_out = 10\n",
        "        self.embedding = nn.Embedding(voca_size, embedding_dim) # Embedding 을 정의 합니다.\n",
        "        self.conv1 = nn.ModuleList(\n",
        "            [nn.Conv2d(1, self.channel_out, (k, embedding_dim)) for k in self.kernel_size]) # Q1)한번 kernel size를 다양하게 만들어볼까요? Q2) 그냥 List 로 하면 안되나요?  안 됩니다.. 그럼 그 안에 있는 애들은 gradient 가 안흐르게 됩니다.  \n",
        "        self.linear1 = nn.Linear(self.channel_out*len(self.kernel_size), 10) #   Channel_out * len(self.kernel_size )-Max Pooling 했기 때문입니다. -> 10 \n",
        "        self.linear2 = nn.Linear(10, 1) # 10 -> 1 Fully Connected Network 를 정의해봅시다. \n",
        "        self.dropout = nn.Dropout() # Drop_out layer 를 정의 해봅니다. default p = 0.5\n",
        "\n",
        "    def forward(self, x):\n",
        "        embed = self.embedding(x)   # (N, L, D)\n",
        "        embed = embed.unsqueeze(1)  # (N,1,L,D), 1: channel_in\n",
        "\n",
        "        # [(N,Channel_out,W,1), ...] * len(Kernel_size)\n",
        "        feature_maps = [F.relu(conv(embed)) for conv in self.conv1] # self.conv1 에 있는 데이터 들을 하나씩 불러오고 그 conv를 각각 적용해봅니다.  -> # N,C,X,1\n",
        "\n",
        "        # [(N,Channel_out,W), ...] * len(Kernel_size)\n",
        "        feature_maps = [feature_map.squeeze(3) for feature_map in feature_maps] # N,1,X,1 -> N,1,X (X인 이유는 Kernel size 마다 다른 결과가 나오기 때문입니다.)\n",
        "        \n",
        "        # [(N, Channel_out), ...] * len(Kernel_size)\n",
        "        pooled_output = [F.max_pool1d(feature_map, feature_map.size(2)) for feature_map in feature_maps] # Max Pooling 을 수행합니다. \n",
        "        output = torch.cat(pooled_output, 1) # pooling 된 결과를 column 에 붙입니다. \n",
        "        output = output.view(output.size(0), -1) # ??\n",
        "        output = self.dropout(output) # Drop out 을 적용해줍니다. (성능을 높히기 위해)\n",
        "        output = F.relu(self.linear1(output)) # fully connected 1  \n",
        "        output = self.dropout(output)  # drop out \n",
        "        output = self.linear2(output) # fully connected 2 \n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jeMwU9-0n1gB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "reg = CNNReg(voca_size = vocab_size,embedding_dim = 256) # CNN기반의 모델을 불러옵니다. \n",
        "reg = reg.cuda()\n",
        "criterion = nn.MSELoss()\n",
        "opt = torch.optim.Adam(reg.parameters(),lr= 0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c8FwfyDZn8nb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "3bac25a5-73be-4159-d7cd-5a8d994c916c"
      },
      "cell_type": "code",
      "source": [
        "train_model(reg,sim_trainDataLoader,criterion,opt)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[+] Training Start \n",
            "[+] End of epoch 1 avg_loss : 0.061\n",
            "[+] End of epoch 2 avg_loss : 0.058\n",
            "[+] End of epoch 3 avg_loss : 0.056\n",
            "[+] End of epoch 4 avg_loss : 0.055\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pbuNtxdWn-v7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "636d8a5c-48a3-4f42-99fe-ea431f6a3ec0"
      },
      "cell_type": "code",
      "source": [
        "test_model(reg,sim_testDataLoader,criterion)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total avg test loss 0.053\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tIAkjv6_sXrw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Pytorch 연습 코드들\n",
        "\n",
        "tutorial : https://github.com/yunjey/pytorch-tutorial \n",
        "\n",
        "PYTORCH Template : https://github.com/victoresque/pytorch-template \n",
        "\n",
        "Advanced \n",
        "\n",
        "Pytorch nmt : https://github.com/OpenNMT/OpenNMT-py \n",
        "\n",
        "Seq2seq  : https://github.com/IBM/pytorch-seq2seq \n",
        "\n",
        "Awesome Pytorch list \n",
        "\n",
        "https://github.com/bharathgs/Awesome-pytorch-list\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "1uYjhqwOpwXa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### model SAVE"
      ]
    },
    {
      "metadata": {
        "id": "w9ybdzTeeAbO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "torch.save(reg.state_dict(), 'rnn_regression.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}